{ 
 "cells": [ 
 { 
 "cell_type": "markdown", 
 "id": "d70b9e71", 
 "metadata": {}, 
 "source": [ 
 "# Ripasso Python + Introduzione a PyTorch / TensorFlow\n", 
 "> Esercitazione (student) - Versione estesa con esempi e esercizi aggiuntivi." 
 ] 
 }, 
 { 
 "cell_type": "markdown", 
 "id": "25d106f9", 
 "metadata": {}, 
 "source": [ 
 "## Setup" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "90a6c78b", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "import numpy as np\n", 
 "import matplotlib.pyplot as plt\n", 
 "np.random.seed(42)\n", 
 "print('Setup completato con successo!')" 
 ] 
 }, 
 { 
 "cell_type": "markdown", 
 "id": "d72f60a7", 
 "metadata": {}, 
 "source": [ 
 "## Ripasso Python (tipi, funzioni, comprehension)" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "35df9535", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# List comprehension: genera quadrati\n", 
 "x = [i*i for i in range(10)]\n", 
 "# Dictionary comprehension: mappa numeri ai loro quadrati\n", 
 "d = {i: i*i for i in range(5)}\n", 
 "print('Lista:', x)\n", 
 "print('Dizionario:', d)" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "35df9536", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# Comprehension con condizioni\n", 
 "pari = [i for i in range(20) if i % 2 == 0]\n", 
 "print('Numeri pari:', pari)\n", 
 "\n", 
 "# Nested comprehension per creare una matrice\n", 
 "matrice = [[i*j for j in range(5)] for i in range(5)]\n", 
 "print('\nTabuada 5x5:')\n", 
 "for riga in matrice:\n", 
 "    print(riga)" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "35df9537", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# Funzioni lambda e map/filter\n", 
 "numeri = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n", 
 "quadrati = list(map(lambda x: x**2, numeri))\n", 
 "dispari = list(filter(lambda x: x % 2 != 0, numeri))\n", 
 "\n", 
 "print('Quadrati:', quadrati)\n", 
 "print('Numeri dispari:', dispari)" 
 ] 
 }, 
 { 
 "cell_type": "markdown", 
 "id": "bffa3b30", 
 "metadata": {}, 
 "source": [ 
 "## Numpy: shape e broadcasting" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "f2069590", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# Broadcasting base\n", 
 "a = np.random.randn(3, 4)\n", 
 "b = np.random.randn(4)\n", 
 "print('Shape a:', a.shape)\n", 
 "print('Shape b:', b.shape)\n", 
 "print('Shape (a+b):', (a+b).shape)\n", 
 "print('\nMatrice a:\n', a)\n", 
 "print('\nVettore b:\n', b)\n", 
 "print('\nSomma a+b (broadcasting):\n', a+b)" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "f2069591", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# Altri esempi di broadcasting\n", 
 "# Broadcasting con colonne\n", 
 "c = np.array([[1], [2], [3]])  # shape (3, 1)\n", 
 "d = np.array([10, 20, 30, 40])  # shape (4,)\n", 
 "risultato = c + d  # shape (3, 4)\n", 
 "\n", 
 "print('Broadcasting colonna + riga:')\n", 
 "print('c shape:', c.shape, '\n', c)\n", 
 "print('d shape:', d.shape, '\n', d)\n", 
 "print('Risultato shape:', risultato.shape, '\n', risultato)" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "f2069592", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# Operazioni vettoriali e matriciali\n", 
 "v1 = np.array([1, 2, 3])\n", 
 "v2 = np.array([4, 5, 6])\n", 
 "\n", 
 "# Prodotto elemento per elemento\n", 
 "print('Prodotto elemento per elemento:', v1 * v2)\n", 
 "\n", 
 "# Prodotto scalare (dot product)\n", 
 "print('Prodotto scalare:', np.dot(v1, v2))\n", 
 "\n", 
 "# Prodotto matriciale\n", 
 "M1 = np.random.randn(3, 4)\n", 
 "M2 = np.random.randn(4, 2)\n", 
 "M_prod = np.dot(M1, M2)  # oppure M1 @ M2\n", 
 "print(f'\nProdotto matriciale: ({M1.shape}) @ ({M2.shape}) = {M_prod.shape}')" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "f2069593", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# Indexing e slicing avanzato\n", 
 "arr = np.arange(24).reshape(4, 6)\n", 
 "print('Array originale:\n', arr)\n", 
 "print('\nPrima riga:', arr[0, :])\n", 
 "print('Seconda colonna:', arr[:, 1])\n", 
 "print('Sottomatrice 2x2:\n', arr[1:3, 2:4])\n", 
 "\n", 
 "# Boolean indexing\n", 
 "print('\nElementi > 10:', arr[arr > 10])" 
 ] 
 }, 
 { 
 "cell_type": "markdown", 
 "id": "a3d0f5d6", 
 "metadata": {}, 
 "source": [ 
 "## PyTorch (se disponibile)" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "9a25ef87", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "try:\n", 
 "    import torch\n", 
 "    t = torch.randn(3, 4)\n", 
 "    print('PyTorch versione:', torch.__version__)\n", 
 "    print('Tensor shape:', t.shape)\n", 
 "    print('Tensor:\n', t)\n", 
 "    \n", 
 "    # Verifica disponibilità GPU\n", 
 "    if torch.cuda.is_available():\n", 
 "        print('\nGPU disponibile:', torch.cuda.get_device_name(0))\n", 
 "    else:\n", 
 "        print('\nGPU non disponibile, usando CPU')\n", 
 "        \n", 
 "except Exception as e:\n", 
 "    print('PyTorch non disponibile:', e)" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "9a25ef88", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# Operazioni con PyTorch\n", 
 "try:\n", 
 "    import torch\n", 
 "    \n", 
 "    # Creazione tensori\n", 
 "    x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n", 
 "    y = torch.ones(2, 2)\n", 
 "    \n", 
 "    print('Tensor x:\n', x)\n", 
 "    print('\nTensor y:\n', y)\n", 
 "    print('\nSomma:\n', x + y)\n", 
 "    print('\nProdotto matriciale:\n', torch.mm(x, y))\n", 
 "    \n", 
 "    # Conversione numpy <-> torch\n", 
 "    np_array = np.array([[1, 2], [3, 4]])\n", 
 "    torch_tensor = torch.from_numpy(np_array)\n", 
 "    back_to_numpy = torch_tensor.numpy()\n", 
 "    print('\nConversione numpy -> torch -> numpy riuscita')\n", 
 "    \n", 
 "except Exception as e:\n", 
 "    print('Operazioni PyTorch non disponibili:', e)" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "9a25ef89", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# Autograd - Differenziazione automatica\n", 
 "try:\n", 
 "    import torch\n", 
 "    \n", 
 "    # Tensor con gradient tracking\n", 
 "    x = torch.tensor([2.0], requires_grad=True)\n", 
 "    y = x ** 2 + 3 * x + 1\n", 
 "    \n", 
 "    print('x =', x.item())\n", 
 "    print('y = x^2 + 3x + 1 =', y.item())\n", 
 "    \n", 
 "    # Calcolo gradiente\n", 
 "    y.backward()\n", 
 "    print('dy/dx = 2x + 3 =', x.grad.item())\n", 
 "    print('Valore atteso: 2*2 + 3 =', 2*2 + 3)\n", 
 "    \n", 
 "except Exception as e:\n", 
 "    print('Autograd non disponibile:', e)" 
 ] 
 }, 
 { 
 "cell_type": "markdown", 
 "id": "3a29b078", 
 "metadata": {}, 
 "source": [ 
 "## TensorFlow (se disponibile)" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "2cb50656", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "try:\n", 
 "    import tensorflow as tf\n", 
 "    x = tf.random.normal((3, 4))\n", 
 "    print('TensorFlow versione:', tf.__version__)\n", 
 "    print('Tensor shape:', x.shape)\n", 
 "    print('Tensor:\n', x.numpy())\n", 
 "    \n", 
 "    # Verifica GPU\n", 
 "    gpus = tf.config.list_physical_devices('GPU')\n", 
 "    if gpus:\n", 
 "        print(f'\nGPU disponibili: {len(gpus)}')\n", 
 "        for gpu in gpus:\n", 
 "            print(f'  - {gpu.name}')\n", 
 "    else:\n", 
 "        print('\nNessuna GPU disponibile, usando CPU')\n", 
 "        \n", 
 "except Exception as e:\n", 
 "    print('TensorFlow non disponibile:', e)" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "2cb50657", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# Operazioni con TensorFlow\n", 
 "try:\n", 
 "    import tensorflow as tf\n", 
 "    \n", 
 "    # Creazione tensori\n", 
 "    a = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n", 
 "    b = tf.ones((2, 2))\n", 
 "    \n", 
 "    print('Tensor a:\n', a.numpy())\n", 
 "    print('\nTensor b:\n', b.numpy())\n", 
 "    print('\nSomma:\n', (a + b).numpy())\n", 
 "    print('\nProdotto matriciale:\n', tf.matmul(a, b).numpy())\n", 
 "    \n", 
 "    # Conversione numpy <-> tensorflow\n", 
 "    np_array = np.array([[1, 2], [3, 4]])\n", 
 "    tf_tensor = tf.convert_to_tensor(np_array)\n", 
 "    back_to_numpy = tf_tensor.numpy()\n", 
 "    print('\nConversione numpy -> tensorflow -> numpy riuscita')\n", 
 "    \n", 
 "except Exception as e:\n", 
 "    print('Operazioni TensorFlow non disponibili:', e)" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "2cb50658", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# GradientTape - Differenziazione automatica\n", 
 "try:\n", 
 "    import tensorflow as tf\n", 
 "    \n", 
 "    x = tf.Variable([2.0])\n", 
 "    \n", 
 "    with tf.GradientTape() as tape:\n", 
 "        y = x ** 2 + 3 * x + 1\n", 
 "    \n", 
 "    print('x =', x.numpy()[0])\n", 
 "    print('y = x^2 + 3x + 1 =', y.numpy()[0])\n", 
 "    \n", 
 "    # Calcolo gradiente\n", 
 "    dy_dx = tape.gradient(y, x)\n", 
 "    print('dy/dx = 2x + 3 =', dy_dx.numpy()[0])\n", 
 "    print('Valore atteso: 2*2 + 3 =', 2*2 + 3)\n", 
 "    \n", 
 "except Exception as e:\n", 
 "    print('GradientTape non disponibile:', e)" 
 ] 
 }, 
 { 
 "cell_type": "markdown", 
 "id": "3565e1dc", 
 "metadata": {}, 
 "source": [ 
 "## Esercizio: standardize(x)\n", 
 "\n", 
 "Implementazione della standardizzazione (z-score normalization): trasforma i dati in modo che abbiano media 0 e deviazione standard 1." 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "5df873fd", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "def standardize(x):\n", 
 "    \"\"\"Standardizza un array: (x - media) / std\"\"\"\n", 
 "    x = np.asarray(x)\n", 
 "    return (x - x.mean()) / (x.std() + 1e-8)\n", 
 "\n", 
 "# Test\n", 
 "z = np.random.randn(1000)\n", 
 "zs = standardize(z)\n", 
 "print('Media dopo standardizzazione:', np.round(zs.mean(), 10))\n", 
 "print('Std dopo standardizzazione:', np.round(zs.std(), 10))\n", 
 "print('\nTest superato!' if abs(zs.mean()) < 1e-10 and abs(zs.std() - 1.0) < 1e-10 else 'Test fallito!')" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "5df873fe", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "# Visualizzazione della standardizzazione\n", 
 "np.random.seed(42)\n", 
 "dati_originali = np.random.randn(1000) * 5 + 10  # media=10, std=5\n", 
 "dati_standardizzati = standardize(dati_originali)\n", 
 "\n", 
 "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n", 
 "\n", 
 "# Istogramma dati originali\n", 
 "axes[0].hist(dati_originali, bins=50, alpha=0.7, color='blue', edgecolor='black')\n", 
 "axes[0].axvline(dati_originali.mean(), color='red', linestyle='--', linewidth=2, label=f'Media: {dati_originali.mean():.2f}')\n", 
 "axes[0].set_title('Dati Originali')\n", 
 "axes[0].set_xlabel('Valore')\n", 
 "axes[0].set_ylabel('Frequenza')\n", 
 "axes[0].legend()\n", 
 "axes[0].grid(True, alpha=0.3)\n", 
 "\n", 
 "# Istogramma dati standardizzati\n", 
 "axes[1].hist(dati_standardizzati, bins=50, alpha=0.7, color='green', edgecolor='black')\n", 
 "axes[1].axvline(dati_standardizzati.mean(), color='red', linestyle='--', linewidth=2, label=f'Media: {dati_standardizzati.mean():.2f}')\n", 
 "axes[1].set_title('Dati Standardizzati')\n", 
 "axes[1].set_xlabel('Valore')\n", 
 "axes[1].set_ylabel('Frequenza')\n", 
 "axes[1].legend()\n", 
 "axes[1].grid(True, alpha=0.3)\n", 
 "\n", 
 "plt.tight_layout()\n", 
 "plt.show()\n", 
 "\n", 
 "print(f'Originali - Media: {dati_originali.mean():.4f}, Std: {dati_originali.std():.4f}')\n", 
 "print(f'Standardizzati - Media: {dati_standardizzati.mean():.4f}, Std: {dati_standardizzati.std():.4f}')" 
 ] 
 }, 
 { 
 "cell_type": "markdown", 
 "id": "ex_add_1", 
 "metadata": {}, 
 "source": [ 
 "## Esercizi Aggiuntivi" 
 ] 
 }, 
 { 
 "cell_type": "markdown", 
 "id": "ex_add_2", 
 "metadata": {}, 
 "source": [ 
 "### Esercizio 1: Normalizzazione Min-Max\n", 
 "\n", 
 "Implementa una funzione che normalizza i dati nell'intervallo [0, 1] usando la formula: `(x - min) / (max - min)`" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "ex_add_3", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "def normalize_minmax(x):\n", 
 "    \"\"\"Normalizza un array nell'intervallo [0, 1]\"\"\"\n", 
 "    x = np.asarray(x)\n", 
 "    x_min = x.min()\n", 
 "    x_max = x.max()\n", 
 "    return (x - x_min) / (x_max - x_min + 1e-8)\n", 
 "\n", 
 "# Test\n", 
 "test_data = np.array([10, 20, 30, 40, 50])\n", 
 "normalized = normalize_minmax(test_data)\n", 
 "print('Dati originali:', test_data)\n", 
 "print('Dati normalizzati:', normalized)\n", 
 "print(f'Min: {normalized.min()}, Max: {normalized.max()}')" 
 ] 
 }, 
 { 
 "cell_type": "markdown", 
 "id": "ex_add_4", 
 "metadata": {}, 
 "source": [ 
 "### Esercizio 2: Softmax\n", 
 "\n", 
 "Implementa la funzione softmax: `softmax(x)_i = exp(x_i) / sum(exp(x_j))`" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "ex_add_5", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "def softmax(x):\n", 
 "    \"\"\"Calcola la funzione softmax\"\"\"\n", 
 "    x = np.asarray(x)\n", 
 "    # Trick per stabilità numerica: sottrai il massimo\n", 
 "    exp_x = np.exp(x - np.max(x))\n", 
 "    return exp_x / exp_x.sum()\n", 
 "\n", 
 "# Test\n", 
 "logits = np.array([2.0, 1.0, 0.1])\n", 
 "probs = softmax(logits)\n", 
 "print('Logits:', logits)\n", 
 "print('Probabilità (softmax):', probs)\n", 
 "print('Somma probabilità:', probs.sum())\n", 
 "\n", 
 "# Visualizzazione\n", 
 "plt.figure(figsize=(10, 4))\n", 
 "plt.subplot(1, 2, 1)\n", 
 "plt.bar(range(len(logits)), logits, color='blue', alpha=0.7)\n", 
 "plt.title('Logits (input)')\n", 
 "plt.xlabel('Classe')\n", 
 "plt.ylabel('Valore')\n", 
 "plt.grid(True, alpha=0.3)\n", 
 "\n", 
 "plt.subplot(1, 2, 2)\n", 
 "plt.bar(range(len(probs)), probs, color='green', alpha=0.7)\n", 
 "plt.title('Probabilità (softmax)')\n", 
 "plt.xlabel('Classe')\n", 
 "plt.ylabel('Probabilità')\n", 
 "plt.ylim([0, 1])\n", 
 "plt.grid(True, alpha=0.3)\n", 
 "\n", 
 "plt.tight_layout()\n", 
 "plt.show()" 
 ] 
 }, 
 { 
 "cell_type": "markdown", 
 "id": "ex_add_6", 
 "metadata": {}, 
 "source": [ 
 "### Esercizio 3: Calcolo della Loss\n", 
 "\n", 
 "Implementa Mean Squared Error (MSE) e Cross-Entropy Loss" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "ex_add_7", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "def mse_loss(y_true, y_pred):\n", 
 "    \"\"\"Mean Squared Error\"\"\"\n", 
 "    return np.mean((y_true - y_pred) ** 2)\n", 
 "\n", 
 "def cross_entropy_loss(y_true, y_pred):\n", 
 "    \"\"\"Cross-Entropy Loss (classificazione binaria)\"\"\"\n", 
 "    epsilon = 1e-8  # per evitare log(0)\n", 
 "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n", 
 "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n", 
 "\n", 
 "# Test MSE\n", 
 "y_true_reg = np.array([1.0, 2.0, 3.0, 4.0])\n", 
 "y_pred_reg = np.array([1.1, 2.2, 2.9, 4.1])\n", 
 "mse = mse_loss(y_true_reg, y_pred_reg)\n", 
 "print(f'MSE Loss: {mse:.4f}')\n", 
 "\n", 
 "# Test Cross-Entropy\n", 
 "y_true_class = np.array([1, 0, 1, 1, 0])\n", 
 "y_pred_class = np.array([0.9, 0.1, 0.8, 0.95, 0.2])\n", 
 "ce = cross_entropy_loss(y_true_class, y_pred_class)\n", 
 "print(f'Cross-Entropy Loss: {ce:.4f}')" 
 ] 
 }, 
 { 
 "cell_type": "markdown", 
 "id": "ex_add_8", 
 "metadata": {}, 
 "source": [ 
 "### Esercizio 4: Mini-batch Generator\n", 
 "\n", 
 "Crea un generatore per iterare sui dati in mini-batch (utile per training di reti neurali)" 
 ] 
 }, 
 { 
 "cell_type": "code", 
 "execution_count": null, 
 "id": "ex_add_9", 
 "metadata": {}, 
 "outputs": [], 
 "source": [ 
 "def batch_generator(X, y, batch_size=32, shuffle=True):\n", 
 "    \"\"\"Generatore di mini-batch per training\"\"\"\n", 
 "    n_samples = len(X)\n", 
 "    indices = np.arange(n_samples)\n", 
 "    \n", 
 "    if shuffle:\n", 
 "        np.random.shuffle(indices)\n", 
 "    \n", 
 "    for start_idx in range(0, n_samples, batch_size):\n", 
 "        end_idx = min(start_idx + batch_size, n_samples)\n", 
 "        batch_indices = indices[start_idx:end_idx]\n", 
 "        yield X[batch_indices], y[batch_indices]\n", 
 "\n", 
 "# Test\n", 
 "X_dummy = np.random.randn(100, 10)  # 100 campioni, 10 features\n", 
 "y_dummy = np.random.randint(0, 2, 100)  # 100 labels binari\n", 
 "\n", 
 "print(f'Dataset: {X_dummy.shape[0]} campioni')\n", 
 "print('\nIterazione sui batch:')\n", 
 "for i, (X_batch, y_batch) in enumerate(batch_generator(X_dummy, y_dummy, batch_size=32)):\n", 
 "    print(f'Batch {i+1}: X shape = {X_batch.shape}, y shape = {y_batch.shape}')" 
 ] 
 }, 
 { 
 "cell_type": "markdown", 
 "id": "summary", 
 "metadata": {}, 
 "source": [ 
 "## Riepilogo\n", 
 "\n", 
 "In questo notebook abbiamo visto:\n", 
 "\n", 
 "1. **Python basics**: comprehension, lambda, map/filter\n", 
 "2. **NumPy**: broadcasting, operazioni matriciali, indexing\n", 
 "3. **PyTorch**: creazione tensori, operazioni, autograd\n", 
 "4. **TensorFlow**: creazione tensori, operazioni, GradientTape\n", 
 "5. **Preprocessing**: standardizzazione, normalizzazione\n", 
 "6. **Funzioni ML**: softmax, loss functions\n", 
 "7. **Utilities**: batch generator per training\n", 
 "\n", 
 "Questi sono i building blocks fondamentali per il deep learning!" 
 ] 
 } 
 ], 
 "metadata": { 
 "kernelspec": { 
 "display_name": "Python 3", 
 "language": "python", 
 "name": "python3" 
 }, 
 "language_info": { 
 "name": "python", 
 "version": "3.8.0" 
 } 
 }, 
 "nbformat": 4, 
 "nbformat_minor": 5 
}